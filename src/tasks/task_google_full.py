import os
import asyncio
import glob
import argparse
import subprocess
import shutil
from dotenv import load_dotenv

import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.x_scraper import XScraper

load_dotenv()

async def main():
    parser = argparse.ArgumentParser(description="X å¹³å°å…¨é‡å†å²åª’ä½“æŠ“å–å¹¶ä¸Šä¼ è‡³ Google Photos")
    parser.add_argument('--users', type=str, required=True, help="é€—å·åˆ†éš”çš„ X ç”¨æˆ·ååˆ—è¡¨")
    args = parser.parse_args()
    
    users = [u.strip() for u in args.users.split(',') if u.strip()]
    cookies_x = os.getenv("TWITTER_COOKIES")
    token_gp = os.getenv("GOOGLE_PHOTOS_TOKEN")
    
    if not token_gp:
        print("âš ï¸ æœªé…ç½® Google Photos Tokenï¼Œæ— æ³•ä¸Šä¼ ï¼")
        return

    try:
         from google_photos_uploader import GooglePhotosUploader
         uploader = GooglePhotosUploader(token_base64=token_gp)
    except ImportError as e:
         print(f"âŒ ç¼ºå°‘ä¾èµ–æ¨¡å—: {e}")
         return
    except Exception as e:
         print(f"âŒ åˆå§‹åŒ– Google Photos å®¢æˆ·ç«¯å¤±è´¥: {e}")
         return
         
    for user in users:
        print(f"\nğŸš€ å¼€å§‹å¤„ç† [å…¨é‡æ¡£æ¡ˆæå–] å¤‡ä»½ä»»åŠ¡: {user}")
        scraper = XScraper(username=user, cookies_raw=cookies_x)
        cookie_file = scraper._prepare_cookies_file()
        
        user_download_dir = scraper.user_download_dir
        if os.path.exists(user_download_dir):
            shutil.rmtree(user_download_dir)
        os.makedirs(user_download_dir, exist_ok=True)
        
        print(f"ğŸ“¥ æ­£åœ¨æ‰§è¡Œ gallery-dl å…¨é‡æ·±åº¦æŠ“å– {user}ï¼Œæ­¤è¿‡ç¨‹å¯èƒ½ä¼šæŒç»­å¾ˆä¹…...")
        # ç›®æ ‡æå–è¯¥ç”¨æˆ·å‘é€çš„æ‰€æœ‰å¸¦åª’ä½“çš„å†…å®¹
        target_url = f"https://x.com/{user}/media"
        
        cmd = [
            "gallery-dl",
            target_url,
            "--directory", user_download_dir,
            "--cookies", cookie_file if cookie_file else ""
        ]
        
        # ç§»é™¤éæ³•ç©ºå‚æ•°
        cmd = [c for c in cmd if c]
        
        try:
            subprocess.run(cmd, check=False)
        except Exception as e:
            print(f"âŒ gallery-dl è¿è¡Œå‡ºé”™ï¼ˆè¯·æ£€æŸ¥æ˜¯å¦å·²å®‰è£… pip install gallery-dlï¼‰: {e}")
        
        # gallery-dl é€šå¸¸ä¼šåˆ›å»ºå¾ˆå¤šå­æ–‡ä»¶å¤¹ï¼Œæˆ‘ä»¬ç”¨ glob é€’å½’æå–æ‰€æœ‰æ–‡ä»¶
        all_files = glob.glob(f"{user_download_dir}/**/*", recursive=True)
        files = [f for f in all_files if os.path.isfile(f)]
        
        if files:
            album_name = f"X_Archive_{user}"
            print(f"â˜ï¸ å‡†å¤‡åˆ†æ‰¹ä¸Šä¼  {len(files)} ä¸ªé«˜æ¸…åª’ä½“æ–‡ä»¶åˆ°ä¸“å±ç›¸å†Œ '{album_name}'...")
            for local_file in files:
                uploader.upload_file(local_file, album_name=album_name)
        else:
            print(f"ğŸ“­ æœªæœªèƒ½ä¸‹è½½åˆ° {user} çš„ä»»ä½•åª’ä½“æ–‡ä»¶ã€‚")

        scraper.cleanup()

if __name__ == "__main__":
    asyncio.run(main())
