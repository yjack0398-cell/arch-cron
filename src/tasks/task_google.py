import os
import asyncio
import glob
import argparse
from dotenv import load_dotenv

import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.x_scraper import XScraper

load_dotenv()

async def main():
    parser = argparse.ArgumentParser(description="X å¹³å°æŠ“å–å¹¶ä¸Šä¼ è‡³ Google Photos å·¥ä½œæµ")
    parser.add_argument('--users', type=str, required=True, help="é€—å·åˆ†éš”çš„ X ç”¨æˆ·ååˆ—è¡¨")
    args = parser.parse_args()
    
    users = [u.strip() for u in args.users.split(',') if u.strip()]
    cookies_x = os.getenv("TWITTER_COOKIES")
    token_gp = os.getenv("GOOGLE_PHOTOS_TOKEN")
    
    if not token_gp:
        print("âš ï¸ æœªé…ç½® Google Photos Tokenï¼Œæ— æ³•ä¸Šä¼ ï¼")
        return

    try:
         from google_photos_uploader import GooglePhotosUploader
         uploader = GooglePhotosUploader(token_base64=token_gp)
    except ImportError as e:
         print(f"âŒ ç¼ºå°‘ä¾èµ–æ¨¡å—: {e}")
         return
    except Exception as e:
         print(f"âŒ åˆå§‹åŒ– Google Photos å®¢æˆ·ç«¯å¤±è´¥: {e}")
         return
         
    for user in users:
        print(f"\nğŸš€ å¼€å§‹å¤„ç† [Google Photos] å¤‡ä»½ä»»åŠ¡: {user}")
        scraper = XScraper(username=user, cookies_raw=cookies_x)
        files = await scraper.fetch_media_files()
        
        if files:
            album_name = f"X_Archive_{user}"
            print(f"â˜ï¸ å‡†å¤‡ä¸Šä¼  {len(files)} ä¸ªæ–‡ä»¶åˆ°ç›¸å†Œ '{album_name}'...")
            for local_file in files:
                uploader.upload_file(local_file, album_name=album_name)

        scraper.cleanup()

if __name__ == "__main__":
    asyncio.run(main())
